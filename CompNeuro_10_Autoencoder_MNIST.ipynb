{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "provenance": [],
      "gpuType": "T4"
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "cells": [
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "W_lMS7LfsVHl"
      },
      "outputs": [],
      "source": [
        "import torch\n",
        "import torch.nn as nn\n",
        "import torchvision.transforms as transforms\n",
        "import torch.optim as optim\n",
        "import torchvision.datasets as datasets\n",
        "from torch.utils.data import DataLoader\n",
        "from tqdm.auto import tqdm\n",
        "import matplotlib.pyplot as plt\n",
        "\n",
        "device = torch.device('cuda' if torch.cuda.is_available() else 'cpu')\n",
        "\n",
        "transform = transforms.Compose([\n",
        "                                transforms.ToTensor(),\n",
        "                                transforms.Normalize((0.5,),(0.5,)),\n",
        "])\n",
        "\n",
        "to_pil_image = transforms.ToPILImage()\n",
        "\n",
        "train_data = datasets.MNIST(\n",
        "    root='input/data',\n",
        "    train=True,\n",
        "    download=True,\n",
        "    transform=transform\n",
        ")\n",
        "print(len(train_data))\n",
        "testimg = train_data[0][0].to(device)\n",
        "batch_size = 2048\n",
        "train_loader = DataLoader(train_data, batch_size=batch_size, shuffle=True)\n",
        "\n",
        "# Autoencoder\n",
        "class Autoencoder(nn.Module):\n",
        "    def __init__(self, input_size, hidden_size):\n",
        "        super().__init__()\n",
        "        self.encoder = nn.Linear(input_size, hidden_size, bias=True)\n",
        "        self.decoder = nn.Linear(hidden_size, input_size, bias=True)\n",
        "\n",
        "    def forward(self, x):\n",
        "        encoded = self.encoder(x)\n",
        "        decoded = self.decoder(encoded)\n",
        "        return encoded, decoded\n",
        "\n",
        "input_size = 784  # Eingabegröße\n",
        "hidden_size = 128  # Größe der versteckten Schicht\n",
        "model = Autoencoder(input_size, hidden_size).to(device)\n",
        "\n",
        "# Optimierer\n",
        "optimizer = optim.Adam(model.parameters(), lr=0.01)\n",
        "\n",
        "enc, test_out = model(testimg.flatten())\n",
        "plt.figure(figsize=[8,8])\n",
        "plt.subplot(2,1,2)\n",
        "plt.plot(torch.sort(torch.abs(enc)).values.detach().cpu().numpy())\n",
        "plt.subplot(2,2,2)\n",
        "plt.imshow(test_out.reshape(28,28).detach().cpu().numpy())\n",
        "plt.subplot(2,2,1)\n",
        "plt.imshow(testimg[0])\n",
        "plt.show()\n",
        "\n",
        "# Trainingsloop\n",
        "num_epochs = 10\n",
        "criterion = nn.MSELoss()\n",
        "\n",
        "# ------------------------------------------------------\n",
        "# --------------- Wähle Maß für Sparsity ---------------\n",
        "sparsity = lambda x: 0.1*torch.mean(torch.abs(x)) # MAE\n",
        "#sparsity = lambda x: 0.1*torch.mean(torch.abs(x)**2) # MSE\n",
        "#sparsity = lambda x: -0.1*torch.mean(torch.softmax(2*x, dim=-1)*torch.log(torch.softmax(2*x, dim=-1))) # Entropie\n",
        "#sparsity = lambda x: 0 # keine Sparsity\n",
        "# ------------------------------------------------------\n",
        "\n",
        "for epoch in range(num_epochs):\n",
        "    for img, _ in tqdm(train_loader):\n",
        "        img = torch.reshape(img, (-1, 784)).to(device)\n",
        "        img_corrupted = img + 0.0*torch.randn(img.shape).to(device)\n",
        "        encoded, reconstructed = model(img_corrupted)\n",
        "\n",
        "        loss = criterion(reconstructed, img)+sparsity(encoded)\n",
        "\n",
        "        optimizer.zero_grad()\n",
        "        loss.backward()\n",
        "        optimizer.step()\n",
        "\n",
        "    if epoch%1==0:\n",
        "        encoded, reconstructed = model(testimg.flatten())\n",
        "        plt.figure(figsize=[8,8])\n",
        "        plt.subplot(2,1,2)\n",
        "        plt.plot(torch.sort(torch.abs(encoded)).values.detach().cpu().numpy())\n",
        "        plt.subplot(2,2,2)\n",
        "        plt.imshow(reconstructed.reshape(28,28).detach().cpu().numpy())\n",
        "        plt.subplot(2,2,1)\n",
        "        plt.imshow(testimg[0])\n",
        "        plt.show()\n",
        "    print(f\"Epoch [{epoch+1}/{num_epochs}], Loss: {loss.item():.4f}\")\n",
        "\n",
        "encoded, reconstructed = model(testimg.flatten())\n",
        "plt.figure(figsize=[8,8])\n",
        "plt.subplot(2,1,2)\n",
        "plt.plot(torch.sort(torch.abs(encoded)).values.detach().cpu().numpy())\n",
        "plt.subplot(2,2,2)\n",
        "plt.imshow(reconstructed.reshape(28,28).detach().cpu().numpy())\n",
        "plt.subplot(2,2,1)\n",
        "plt.imshow(testimg[0])\n",
        "plt.show()\n"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "for i in range(10):\n",
        "    testimg_corrupted = train_data[i][0] + 0.0*torch.randn(testimg.shape)\n",
        "    plt.figure()\n",
        "    plt.subplot(1,3,1)\n",
        "    plt.imshow(testimg_corrupted[0])\n",
        "    plt.subplot(1,3,2)\n",
        "    plt.imshow(model(testimg_corrupted.flatten())[1].reshape(28,28).detach().cpu().numpy())\n",
        "    plt.subplot(1,3,3)\n",
        "    plt.imshow(train_data[i][0][0])\n",
        "    plt.show()"
      ],
      "metadata": {
        "id": "wjdHzOaSvdqV"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "from torchvision.utils import make_grid\n",
        "enc = model.decoder.weight.data.t()\n",
        "print(enc.shape)\n",
        "enc -= torch.min(enc, axis=-1, keepdim=True).values\n",
        "enc /= torch.max(enc)\n",
        "enc = enc.reshape(-1, 1, 28,28)\n",
        "image_enc = make_grid(enc)\n",
        "print(image_enc.shape)\n",
        "plt.figure(figsize=[10,20])\n",
        "plt.imshow(image_enc.transpose(0,1).transpose(1,2))\n",
        "plt.show()\n",
        "\n",
        "plt.figure()\n",
        "plt.imshow(model.decoder.bias.data.reshape(28,28))\n",
        "plt.show()"
      ],
      "metadata": {
        "id": "SyD93FoBxAUR"
      },
      "execution_count": null,
      "outputs": []
    }
  ]
}